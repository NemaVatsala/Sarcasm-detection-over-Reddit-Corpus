# -*- coding: utf-8 -*-
"""NLP-project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XrbJf4ij5vfzG5tqarrKe60dKI2RRum

**Importing libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS

"""**Importing CSV files**"""

train_df = pd.read_csv("/content/project_training_data_with_class_labels.csv", error_bad_lines=False)

train_df

test_df = pd.read_csv("/content/project_test_data.csv", error_bad_lines=False)

test_df

"""**Cleaning the dataset**"""

df1 = train_df[train_df.isna().any(axis=1)]

df1

train_df.dropna()

df2 = test_df[test_df.isna().any(axis=1)]

df2

test_df.dropna()

train_df.rename(columns = {' Class Labels ':'label'}, inplace = True)

train_df['label'].replace(['non-sarcastic','sarcastic'],[1,0], inplace = True)

train_df.head()

train_df.info()

test_df.info()

"""**Exploratory Data Analysis**"""

# to check number of sarcastic and non-sarcastic comments
train_df['label'].value_counts()

"""Almost equal number of sarcastic and non-sarcastic comments."""

print(train_df['label'].value_counts()/len(train_df))

plt.figure(figsize=(5,5))
ax = sns.countplot(x='label',  data= train_df)
ax.set(title = "Distribution of Classes", xlabel="Sarcasm Status", ylabel = "Total Count")
total = float(len(train_df))
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x()+p.get_width()/2.,
            height + 3,
            '{:1.1f}%'.format((height/total)*100),
            ha="center") 
plt.show()

# To check if there is any relation between the length of the comment and its label
#train_df.loc[train_df,'Comments'].str.len().apply(np.log1p).hist(label='sarcastic,alpha=.5)
train_df.loc[train_df['label']==1,'Comments'].str.len().apply(np.log1p).hist(label='sarcastic', alpha=.5)
train_df.loc[train_df['label']==0,'Comments'].str.len().apply(np.log1p).hist(label='non-sarcastic', alpha=.5)
plt.legend()
plt.title('Natural Log Length of Comments')
plt.show()

"""Sarcastic comments are normally distributed in length. Non-sarcastic comments has a right-skew."""

# Most common words in the sarcastic comments 
wordcloud = WordCloud(background_color='black', stopwords = STOPWORDS,
                max_words = 200, max_font_size = 100, 
                random_state = 17, width=800, height=400)

plt.figure(figsize=(12, 12))
wordcloud.generate(str(train_df.loc[train_df['label'] == 1, 'Parent Comments']))
plt.grid(b= False)
plt.imshow(wordcloud);

# Comparing sarcastic comments with Parent comments
sarcasm_comm_len = np.array(train_df.loc[train_df['label'] == 1]['Comments'].str.len())
parent_comm_len = np.array(train_df.loc[train_df['label'] == 1]['Parent Comments'].str.len())
ratio_len = np.array((train_df.loc[train_df['label'] == 1]['Comments'].str.len())/(train_df.loc[train_df['label'] == 1]['Parent Comments'].str.len()))

d = pd.DataFrame({'Comment Length': sarcasm_comm_len, 'Parent Comment Length': parent_comm_len, 'Ratio Length': ratio_len}, columns=['Comment Length', 'Parent Comment Length', 'Ratio Length'])

ax = plt.axes()
sns.scatterplot(data=d, x="Comment Length", y="Parent Comment Length",  size=ratio_len)
ax.set_title("Comparing Sarcastic Comment Length with Parent Comment")
# control x and y limits
plt.ylim(0, 12000)
plt.xlim(0, 800)
plt.show()

from nltk.tokenize import word_tokenize, sent_tokenize, wordpunct_tokenize, TreebankWordTokenizer, TweetTokenizer, MWETokenizer
from nltk.corpus import stopwords
from nltk import ngrams
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

corpus = train_df['Comments'].astype(str)

corpus

"""Tfidf vectorizer

Stop words removed
"""

vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1,1))
X = vectorizer.fit_transform(corpus.values.astype('U'))

X=X.toarray()